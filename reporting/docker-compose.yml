version: '2'

services:

  # Log and event processing for reporting/debugging (ELK stack)
  # -------------------------------------------------------------

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${TAG}
    environment: ['http.host=0.0.0.0', 'transport.host=127.0.0.1', 'xpack.security.enabled=false']
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:${TAG}
    command: [ "/bin/bash", "-c", "/usr/share/kibana/bin/kibana-plugin remove x-pack; /usr/local/bin/kibana-docker" ]
    ports:
      - "5601:5601"
    depends_on: ['elasticsearch']

  # Logstash with knowledge of how to parse Heritrix3 crawl log files
  logstash-crawl-logs:
    image: docker.elastic.co/logstash/logstash:${TAG}
    ports:
      - "9600:9600"
      - "5044:5044"
    volumes:
      - ./logstash/pipelines/heritrix-crawl-log-pipeline.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on: ['elasticsearch', 'kafka']

  # Logstash with knowledge of how to parse web access log files
  logstash-www-logs:
    image: docker.elastic.co/logstash/logstash:${TAG}
    ports:
      - "9601:9600"
      - "5045:5044"
    volumes:
      - ./logstash/pipelines/access-www-log-pipeline.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on: ['elasticsearch', 'kafka']

  # Kafka used as main mechanism for routing data for monitoring
  # Needs a Zookeeper too
  # ----
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: gleam.local
      KAFKA_CREATE_TOPICS: "test:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
